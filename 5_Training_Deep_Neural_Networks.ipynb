{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_Training_Deep_Neural_Networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOEhrTVH1Jl1K5eSOcb+6Cs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhavgupta1/Deep-Learning-Using-TensorFlow/blob/master/5_Training_Deep_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yC6jCBi0eBOG"
      },
      "source": [
        "#**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLAs1yE64kZh",
        "outputId": "9b2d07fd-1cce-4fc9-8041-99e6ff5545bc"
      },
      "source": [
        "!ls\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "import os\n",
        "os.chdir(\"drive/\")\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.23-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "'Capstone Project Submission .desktop'\t\t     model_ckps10\n",
            "'Capstone Project Submission  (Responses).desktop'   model_ckps2\n",
            "'Colab Notebooks'\t\t\t\t     model_ckps3\n",
            " data\t\t\t\t\t\t     model_ckps4\n",
            " Dataset\t\t\t\t\t     model_ckps5\n",
            " drive\t\t\t\t\t\t     model_ckps6\n",
            "'Getting started'\t\t\t\t     model_ckps7\n",
            " images\t\t\t\t\t\t     model_ckps8\n",
            " import\t\t\t\t\t\t     model_ckps9\n",
            " model_ckps\t\t\t\t\t     model_ckps_normal_gd\n",
            " model_ckps1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NGp9k_-EHjsJ",
        "outputId": "37748dc6-f2a3-4133-a0d1-e0179f7ce085"
      },
      "source": [
        "!pip install tensorflow==1.10.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/e6/a6d371306c23c2b01cd2cb38909673d17ddd388d9e4b3c0f6602bfd972c8/tensorflow-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
            "\u001b[K     |████████████████████████████████| 58.4MB 76kB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.1.0)\n",
            "Collecting numpy<=1.14.5,>=1.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 5.8MB/s \n",
            "\u001b[?25hCollecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.35.1)\n",
            "Collecting tensorboard<1.11.0,>=1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.3.3)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.33.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (3.4.0)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement setuptools>=41.2, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tifffile 2020.9.3 has requirement numpy>=1.15.1, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.11.0 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 1.1.4 has requirement numpy>=1.15.4, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: numba 0.48.0 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.17.2 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement numpy>=1.15.4, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.4.1 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.1 has requirement numpy>=1.16, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, setuptools, tensorboard, tensorflow\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: setuptools 50.3.2\n",
            "    Uninstalling setuptools-50.3.2:\n",
            "      Successfully uninstalled setuptools-50.3.2\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed numpy-1.14.5 setuptools-39.1.0 tensorboard-1.10.0 tensorflow-1.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqLgCrtT4qOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35546b67-d22b-4831-af0e-c8c8e1f92787"
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# To plot pretty figures\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "from functools import partial\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "from matplotlib.colors import ListedColormap\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8T4M6N94xpT"
      },
      "source": [
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"deep\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQfDEFLkXs_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565beddb-44b4-4dcb-d3a3-326739ac6261"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"data/\")\n",
        "X_train = mnist.train.images\n",
        "X_test = mnist.test.images\n",
        "y_train = mnist.train.labels.astype(\"int\")\n",
        "y_test = mnist.test.labels.astype(\"int\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-36e6f08442f0>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2dZPuh44eC_"
      },
      "source": [
        "n_inputs = 28 * 28  # MNIST\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 50\n",
        "n_hidden3 = 50\n",
        "n_hidden4 = 50\n",
        "n_hidden5 = 50\n",
        "n_outputs = 10"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBawdVU8MO5K"
      },
      "source": [
        "learning_rate = 0.001"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVjPai1cMIV9"
      },
      "source": [
        "n_epochs = 40\n",
        "batch_size = 50"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUsp70wqXeRR"
      },
      "source": [
        "#**Fast Optimizers**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKBU-CyjGm-n"
      },
      "source": [
        "##**Normal GD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1VOL3vzERUL"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ladzjBpMUQV"
      },
      "source": [
        "# Create a simple neural net for MNIST and add gradient clipping\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.selu, name=\"hidden1\",kernel_initializer=he_init)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.selu, name=\"hidden2\",kernel_initializer=he_init)\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.selu, name=\"hidden3\",kernel_initializer=he_init)\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.selu, name=\"hidden4\",kernel_initializer=he_init)\n",
        "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.selu, name=\"hidden5\",kernel_initializer=he_init)\n",
        "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXuQHgc3Ez8H"
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-blTtNvFYAR"
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmVgkIC3FUzv"
      },
      "source": [
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38Upb_P9NXaj"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otfba_mPF-Zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f42346b-54c0-48b3-e1a2-0cb2b35d05fd"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,y: mnist.test.labels})\n",
        "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"model_ckps_normal_gd/my_model_final.ckpt\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Test accuracy: 0.8586\n",
            "1 Test accuracy: 0.8926\n",
            "2 Test accuracy: 0.9079\n",
            "3 Test accuracy: 0.9171\n",
            "4 Test accuracy: 0.921\n",
            "5 Test accuracy: 0.925\n",
            "6 Test accuracy: 0.9274\n",
            "7 Test accuracy: 0.9313\n",
            "8 Test accuracy: 0.9327\n",
            "9 Test accuracy: 0.9335\n",
            "10 Test accuracy: 0.9381\n",
            "11 Test accuracy: 0.9392\n",
            "12 Test accuracy: 0.941\n",
            "13 Test accuracy: 0.9433\n",
            "14 Test accuracy: 0.9432\n",
            "15 Test accuracy: 0.9453\n",
            "16 Test accuracy: 0.9452\n",
            "17 Test accuracy: 0.9459\n",
            "18 Test accuracy: 0.9484\n",
            "19 Test accuracy: 0.949\n",
            "20 Test accuracy: 0.9482\n",
            "21 Test accuracy: 0.9495\n",
            "22 Test accuracy: 0.9508\n",
            "23 Test accuracy: 0.9529\n",
            "24 Test accuracy: 0.9525\n",
            "25 Test accuracy: 0.954\n",
            "26 Test accuracy: 0.9542\n",
            "27 Test accuracy: 0.9543\n",
            "28 Test accuracy: 0.9549\n",
            "29 Test accuracy: 0.9561\n",
            "30 Test accuracy: 0.9555\n",
            "31 Test accuracy: 0.9559\n",
            "32 Test accuracy: 0.9563\n",
            "33 Test accuracy: 0.9577\n",
            "34 Test accuracy: 0.9565\n",
            "35 Test accuracy: 0.9581\n",
            "36 Test accuracy: 0.9596\n",
            "37 Test accuracy: 0.959\n",
            "38 Test accuracy: 0.959\n",
            "39 Test accuracy: 0.9607\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNWKpoz-HQYi"
      },
      "source": [
        "##**Momentum GD**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tc5ImnduPqRU"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuZjpz7wHQYj"
      },
      "source": [
        "# Create a simple neural net for MNIST and add gradient clipping\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.selu, name=\"hidden1\",kernel_initializer=he_init)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.selu, name=\"hidden2\",kernel_initializer=he_init)\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.selu, name=\"hidden3\",kernel_initializer=he_init)\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.selu, name=\"hidden4\",kernel_initializer=he_init)\n",
        "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.selu, name=\"hidden5\",kernel_initializer=he_init)\n",
        "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-EmhbRCHQYj"
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CUnqQBkHQYj"
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WtRP13rHQYj"
      },
      "source": [
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZLk0z6ENqlk"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6k7ke73HQYj",
        "outputId": "9a779f2d-3db9-415b-cdc8-ac536bdb23a0"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,y: mnist.test.labels})\n",
        "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"model_ckps_momentum/my_model_final.ckpt\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Test accuracy: 0.9337\n",
            "1 Test accuracy: 0.9461\n",
            "2 Test accuracy: 0.9526\n",
            "3 Test accuracy: 0.9549\n",
            "4 Test accuracy: 0.9593\n",
            "5 Test accuracy: 0.9622\n",
            "6 Test accuracy: 0.9633\n",
            "7 Test accuracy: 0.9632\n",
            "8 Test accuracy: 0.9658\n",
            "9 Test accuracy: 0.9671\n",
            "10 Test accuracy: 0.9681\n",
            "11 Test accuracy: 0.9713\n",
            "12 Test accuracy: 0.9712\n",
            "13 Test accuracy: 0.9702\n",
            "14 Test accuracy: 0.9724\n",
            "15 Test accuracy: 0.9716\n",
            "16 Test accuracy: 0.9716\n",
            "17 Test accuracy: 0.9709\n",
            "18 Test accuracy: 0.9715\n",
            "19 Test accuracy: 0.9733\n",
            "20 Test accuracy: 0.9729\n",
            "21 Test accuracy: 0.9716\n",
            "22 Test accuracy: 0.9716\n",
            "23 Test accuracy: 0.9721\n",
            "24 Test accuracy: 0.9733\n",
            "25 Test accuracy: 0.9726\n",
            "26 Test accuracy: 0.9723\n",
            "27 Test accuracy: 0.9736\n",
            "28 Test accuracy: 0.9725\n",
            "29 Test accuracy: 0.9732\n",
            "30 Test accuracy: 0.9739\n",
            "31 Test accuracy: 0.9728\n",
            "32 Test accuracy: 0.974\n",
            "33 Test accuracy: 0.9746\n",
            "34 Test accuracy: 0.9737\n",
            "35 Test accuracy: 0.9735\n",
            "36 Test accuracy: 0.9751\n",
            "37 Test accuracy: 0.9739\n",
            "38 Test accuracy: 0.9744\n",
            "39 Test accuracy: 0.9746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpyW3KNpHqow"
      },
      "source": [
        "##**Nestrov**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-_08WLFPtWL"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGwVI9y_Hqow"
      },
      "source": [
        "# Create a simple neural net for MNIST and add gradient clipping\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.selu, name=\"hidden1\",kernel_initializer=he_init)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.selu, name=\"hidden2\",kernel_initializer=he_init)\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.selu, name=\"hidden3\",kernel_initializer=he_init)\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.selu, name=\"hidden4\",kernel_initializer=he_init)\n",
        "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.selu, name=\"hidden5\",kernel_initializer=he_init)\n",
        "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-gosL9gHqox"
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pR5lX1L0Hqox"
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljIgcbhiHqox"
      },
      "source": [
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.MomentumOptimizer(learning_rate=learning_rate,momentum=0.9, use_nesterov=True)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-TL0QNINsVg"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urjGmEAgHqox",
        "outputId": "b30fb320-473b-48d3-8b36-cd546bbd9087"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,y: mnist.test.labels})\n",
        "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"model_ckps_nestrov/my_model_final.ckpt\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Test accuracy: 0.9321\n",
            "1 Test accuracy: 0.9453\n",
            "2 Test accuracy: 0.9516\n",
            "3 Test accuracy: 0.9586\n",
            "4 Test accuracy: 0.9606\n",
            "5 Test accuracy: 0.9625\n",
            "6 Test accuracy: 0.9635\n",
            "7 Test accuracy: 0.9648\n",
            "8 Test accuracy: 0.9664\n",
            "9 Test accuracy: 0.9678\n",
            "10 Test accuracy: 0.9675\n",
            "11 Test accuracy: 0.9651\n",
            "12 Test accuracy: 0.9701\n",
            "13 Test accuracy: 0.968\n",
            "14 Test accuracy: 0.9679\n",
            "15 Test accuracy: 0.9704\n",
            "16 Test accuracy: 0.9688\n",
            "17 Test accuracy: 0.9701\n",
            "18 Test accuracy: 0.9722\n",
            "19 Test accuracy: 0.97\n",
            "20 Test accuracy: 0.973\n",
            "21 Test accuracy: 0.9711\n",
            "22 Test accuracy: 0.972\n",
            "23 Test accuracy: 0.9708\n",
            "24 Test accuracy: 0.9714\n",
            "25 Test accuracy: 0.9712\n",
            "26 Test accuracy: 0.9714\n",
            "27 Test accuracy: 0.9698\n",
            "28 Test accuracy: 0.969\n",
            "29 Test accuracy: 0.9713\n",
            "30 Test accuracy: 0.971\n",
            "31 Test accuracy: 0.9722\n",
            "32 Test accuracy: 0.9733\n",
            "33 Test accuracy: 0.9733\n",
            "34 Test accuracy: 0.9712\n",
            "35 Test accuracy: 0.9722\n",
            "36 Test accuracy: 0.9728\n",
            "37 Test accuracy: 0.9725\n",
            "38 Test accuracy: 0.9719\n",
            "39 Test accuracy: 0.9724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO_jbZgGH-FR"
      },
      "source": [
        "##**Adagrad**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw9UimIoPxCO"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vg3LUCIAH-FR"
      },
      "source": [
        "# Create a simple neural net for MNIST and add gradient clipping\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.selu, name=\"hidden1\",kernel_initializer=he_init)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.selu, name=\"hidden2\",kernel_initializer=he_init)\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.selu, name=\"hidden3\",kernel_initializer=he_init)\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.selu, name=\"hidden4\",kernel_initializer=he_init)\n",
        "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.selu, name=\"hidden5\",kernel_initializer=he_init)\n",
        "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbhm5aA8H-FR"
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy2MsLmRH-FR"
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f4FCw_ZH-FR"
      },
      "source": [
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AItRQd_jNtyh"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dtlu5pOZH-FR",
        "outputId": "ceb417c7-6979-4a3c-fc5f-92323944dc72"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,y: mnist.test.labels})\n",
        "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"model_ckps_adagrad/my_model_final.ckpt\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Test accuracy: 0.8903\n",
            "1 Test accuracy: 0.9108\n",
            "2 Test accuracy: 0.9194\n",
            "3 Test accuracy: 0.9258\n",
            "4 Test accuracy: 0.9296\n",
            "5 Test accuracy: 0.9331\n",
            "6 Test accuracy: 0.9347\n",
            "7 Test accuracy: 0.9377\n",
            "8 Test accuracy: 0.9384\n",
            "9 Test accuracy: 0.9401\n",
            "10 Test accuracy: 0.9416\n",
            "11 Test accuracy: 0.9419\n",
            "12 Test accuracy: 0.9427\n",
            "13 Test accuracy: 0.9441\n",
            "14 Test accuracy: 0.9455\n",
            "15 Test accuracy: 0.9452\n",
            "16 Test accuracy: 0.9462\n",
            "17 Test accuracy: 0.9465\n",
            "18 Test accuracy: 0.9476\n",
            "19 Test accuracy: 0.949\n",
            "20 Test accuracy: 0.9483\n",
            "21 Test accuracy: 0.9497\n",
            "22 Test accuracy: 0.9508\n",
            "23 Test accuracy: 0.9508\n",
            "24 Test accuracy: 0.951\n",
            "25 Test accuracy: 0.9525\n",
            "26 Test accuracy: 0.953\n",
            "27 Test accuracy: 0.9534\n",
            "28 Test accuracy: 0.9538\n",
            "29 Test accuracy: 0.9546\n",
            "30 Test accuracy: 0.9544\n",
            "31 Test accuracy: 0.9549\n",
            "32 Test accuracy: 0.9555\n",
            "33 Test accuracy: 0.9559\n",
            "34 Test accuracy: 0.9567\n",
            "35 Test accuracy: 0.9565\n",
            "36 Test accuracy: 0.9565\n",
            "37 Test accuracy: 0.9572\n",
            "38 Test accuracy: 0.9573\n",
            "39 Test accuracy: 0.957\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sEoimFoIQNS"
      },
      "source": [
        "##**RMS Prop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFtyf089Pzvv"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3XQOGGUIQNS"
      },
      "source": [
        "# Create a simple neural net for MNIST and add gradient clipping\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.selu, name=\"hidden1\",kernel_initializer=he_init)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.selu, name=\"hidden2\",kernel_initializer=he_init)\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.selu, name=\"hidden3\",kernel_initializer=he_init)\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.selu, name=\"hidden4\",kernel_initializer=he_init)\n",
        "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.selu, name=\"hidden5\",kernel_initializer=he_init)\n",
        "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-aVBknjIQNS"
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxlTi8jUIQNS"
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVX9YT2TIQNS"
      },
      "source": [
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate,momentum=0.9, decay=0.9, epsilon=1e-10)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFWl_SMDNvjj"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SaPWJPx0IQNT",
        "outputId": "f30260c7-1f77-4db6-aaf1-ca69c2d656ee"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,y: mnist.test.labels})\n",
        "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"model_ckps_rms_prop/my_model_final.ckpt\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Test accuracy: 0.9275\n",
            "1 Test accuracy: 0.9454\n",
            "2 Test accuracy: 0.9457\n",
            "3 Test accuracy: 0.9532\n",
            "4 Test accuracy: 0.9548\n",
            "5 Test accuracy: 0.9393\n",
            "6 Test accuracy: 0.9602\n",
            "7 Test accuracy: 0.9499\n",
            "8 Test accuracy: 0.9634\n",
            "9 Test accuracy: 0.9474\n",
            "10 Test accuracy: 0.9601\n",
            "11 Test accuracy: 0.9469\n",
            "12 Test accuracy: 0.952\n",
            "13 Test accuracy: 0.9569\n",
            "14 Test accuracy: 0.9456\n",
            "15 Test accuracy: 0.9516\n",
            "16 Test accuracy: 0.9484\n",
            "17 Test accuracy: 0.9487\n",
            "18 Test accuracy: 0.9402\n",
            "19 Test accuracy: 0.9304\n",
            "20 Test accuracy: 0.9503\n",
            "21 Test accuracy: 0.9482\n",
            "22 Test accuracy: 0.9326\n",
            "23 Test accuracy: 0.8531\n",
            "24 Test accuracy: 0.9257\n",
            "25 Test accuracy: 0.8474\n",
            "26 Test accuracy: 0.8381\n",
            "27 Test accuracy: 0.7875\n",
            "28 Test accuracy: 0.8545\n",
            "29 Test accuracy: 0.8462\n",
            "30 Test accuracy: 0.8529\n",
            "31 Test accuracy: 0.8016\n",
            "32 Test accuracy: 0.8231\n",
            "33 Test accuracy: 0.8422\n",
            "34 Test accuracy: 0.7749\n",
            "35 Test accuracy: 0.5961\n",
            "36 Test accuracy: 0.7286\n",
            "37 Test accuracy: 0.8469\n",
            "38 Test accuracy: 0.8521\n",
            "39 Test accuracy: 0.8532\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvFD9qKuIxO6"
      },
      "source": [
        "##**Adam**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83tvffsmP5gb"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
        "he_init = tf.contrib.layers.variance_scaling_initializer()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz_oVOR2IxO6"
      },
      "source": [
        "# Create a simple neural net for MNIST and add gradient clipping\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.selu, name=\"hidden1\",kernel_initializer=he_init)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.selu, name=\"hidden2\",kernel_initializer=he_init)\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, activation=tf.nn.selu, name=\"hidden3\",kernel_initializer=he_init)\n",
        "    hidden4 = tf.layers.dense(hidden3, n_hidden4, activation=tf.nn.selu, name=\"hidden4\",kernel_initializer=he_init)\n",
        "    hidden5 = tf.layers.dense(hidden4, n_hidden5, activation=tf.nn.selu, name=\"hidden5\",kernel_initializer=he_init)\n",
        "    logits = tf.layers.dense(hidden5, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emTPbfRNIxO6"
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fl3Krb2IxO6"
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbMvnvgwIxO6"
      },
      "source": [
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZYSGRD8Nw5-"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC32lGVUIxO6",
        "outputId": "31625600-d363-4d16-fd30-fa3a0c999322"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val = accuracy.eval(feed_dict={X: mnist.test.images,y: mnist.test.labels})\n",
        "        print(epoch, \"Test accuracy:\", accuracy_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"model_ckps_adam/my_model_final.ckpt\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Test accuracy: 0.9478\n",
            "1 Test accuracy: 0.9526\n",
            "2 Test accuracy: 0.9571\n",
            "3 Test accuracy: 0.9635\n",
            "4 Test accuracy: 0.9659\n",
            "5 Test accuracy: 0.9653\n",
            "6 Test accuracy: 0.9659\n",
            "7 Test accuracy: 0.9681\n",
            "8 Test accuracy: 0.9686\n",
            "9 Test accuracy: 0.9685\n",
            "10 Test accuracy: 0.9734\n",
            "11 Test accuracy: 0.9729\n",
            "12 Test accuracy: 0.9674\n",
            "13 Test accuracy: 0.9762\n",
            "14 Test accuracy: 0.9743\n",
            "15 Test accuracy: 0.9738\n",
            "16 Test accuracy: 0.9715\n",
            "17 Test accuracy: 0.976\n",
            "18 Test accuracy: 0.975\n",
            "19 Test accuracy: 0.9732\n",
            "20 Test accuracy: 0.9729\n",
            "21 Test accuracy: 0.9694\n",
            "22 Test accuracy: 0.975\n",
            "23 Test accuracy: 0.9748\n",
            "24 Test accuracy: 0.9748\n",
            "25 Test accuracy: 0.9763\n",
            "26 Test accuracy: 0.9732\n",
            "27 Test accuracy: 0.9746\n",
            "28 Test accuracy: 0.9735\n",
            "29 Test accuracy: 0.9751\n",
            "30 Test accuracy: 0.9711\n",
            "31 Test accuracy: 0.9754\n",
            "32 Test accuracy: 0.9725\n",
            "33 Test accuracy: 0.978\n",
            "34 Test accuracy: 0.9759\n",
            "35 Test accuracy: 0.9781\n",
            "36 Test accuracy: 0.9783\n",
            "37 Test accuracy: 0.9771\n",
            "38 Test accuracy: 0.9763\n",
            "39 Test accuracy: 0.979\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}