{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_Training_an_MNIST_DATA_with_Plain_TensorFlow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3mJBXeNTC6/3HcD5/kAmL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anubhavgupta1/Deep-Learning-Using-TensorFlow/blob/master/2_Training_an_MNIST_DATA_with_Plain_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPblYsARL8E6",
        "outputId": "00ab7359-3c62-4871-eb00-e28adcd8d4fc"
      },
      "source": [
        "!ls\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive\n",
        "\n",
        "import os\n",
        "os.chdir(\"drive/\")\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n",
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 144865 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.23-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n",
            "'Capstone Project Submission .desktop'\t\t    'Getting started'\n",
            "'Capstone Project Submission  (Responses).desktop'   images\n",
            "'Colab Notebooks'\t\t\t\t     import\n",
            " data\t\t\t\t\t\t     model_ckps\n",
            " Dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NGp9k_-EHjsJ",
        "outputId": "4d65fa6f-fdae-4fa8-9ab4-ddf39ae5e151"
      },
      "source": [
        "!pip install tensorflow==1.10.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/e6/a6d371306c23c2b01cd2cb38909673d17ddd388d9e4b3c0f6602bfd972c8/tensorflow-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (58.4MB)\n",
            "\u001b[K     |████████████████████████████████| 58.4MB 82kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.3.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.33.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.35.1)\n",
            "Collecting numpy<=1.14.5,>=1.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/68/1e/116ad560de97694e2d0c1843a7a0075cc9f49e922454d32f49a80eb6f1f2/numpy-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 45.6MB/s \n",
            "\u001b[?25hCollecting setuptools<=39.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
            "\u001b[K     |████████████████████████████████| 573kB 31.1MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.11.0,>=1.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.10.0) (1.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (1.0.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (2.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.11.0,>=1.10.0->tensorflow==1.10.0) (3.4.0)\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: xarray 0.15.1 has requirement setuptools>=41.2, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tifffile 2020.9.3 has requirement numpy>=1.15.1, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: spacy 2.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: seaborn 0.11.0 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pandas 1.1.4 has requirement numpy>=1.15.4, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: numba 0.48.0 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-auth 1.17.2 has requirement setuptools>=40.3.0, but you'll have setuptools 39.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement numpy>=1.15.4, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: cvxpy 1.0.31 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: blis 0.4.1 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: astropy 4.1 has requirement numpy>=1.16, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, setuptools, tensorboard, tensorflow\n",
            "  Found existing installation: numpy 1.18.5\n",
            "    Uninstalling numpy-1.18.5:\n",
            "      Successfully uninstalled numpy-1.18.5\n",
            "  Found existing installation: setuptools 50.3.2\n",
            "    Uninstalling setuptools-50.3.2:\n",
            "      Successfully uninstalled setuptools-50.3.2\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed numpy-1.14.5 setuptools-39.1.0 tensorboard-1.10.0 tensorflow-1.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf_23B1kF5Ob",
        "outputId": "2c2017e6-952b-4c31-ca0d-5f04d18bc783"
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57gIAWYjGx35"
      },
      "source": [
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"ann\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yQB0s8iHBYc"
      },
      "source": [
        "#**FNN for MNIST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKbMpMkVsV_e"
      },
      "source": [
        "##**Using plain TensorFlow**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVv1ZiOMPMbL",
        "outputId": "fd352045-fd91-47bd-dc4d-3d64107a6e49"
      },
      "source": [
        "mnist = input_data.read_data_sets(\"data/\")\n",
        "mnist"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-148c564f7b3c>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting data/train-labels-idx1-ubyte.gz\n",
            "Extracting data/t10k-images-idx3-ubyte.gz\n",
            "Extracting data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f24701aecf8>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f247eecf2b0>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f247eecf198>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "PVBFjipkPPUZ",
        "outputId": "0f244f10-9f0b-451c-beca-915017e34b46"
      },
      "source": [
        "print(type(mnist))\n",
        "X_train = mnist.train.images\n",
        "X_test = mnist.test.images\n",
        "y_train = mnist.train.labels.astype(\"int\")\n",
        "y_test = mnist.test.labels.astype(\"int\")\n",
        "print(X_train[1].shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(X_train[1].reshape(28, -1).shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)\n",
        "print(y_train[1])\n",
        "plt.imshow(X_train[1].reshape(28, -1))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.contrib.learn.python.learn.datasets.base.Datasets'>\n",
            "(784,)\n",
            "(55000, 784)\n",
            "(10000, 784)\n",
            "(28, 28)\n",
            "(55000,)\n",
            "(10000,)\n",
            "3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f246e93b4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCwrbr4fMuYZ"
      },
      "source": [
        "###**1. Construction Phase**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCpcMKqaMtgd",
        "outputId": "95d23308-6367-4591-c246-a442609a95fc"
      },
      "source": [
        "print(len(X_train[0]))\n",
        "n_inputs = 28*28  # MNIST\n",
        "n_hidden1 = 100\n",
        "n_hidden2 = 200\n",
        "n_hidden3 = 300\n",
        "n_outputs = 10"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2esKttJM2sM"
      },
      "source": [
        "###**2. Defining placeholders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1ufx4krNKW9"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UEvYhS5ejZi",
        "outputId": "1223869f-8750-4d36-c6e1-ce0373444b4d"
      },
      "source": [
        "print(X.get_shape())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQUdbFZSe90t",
        "outputId": "ab8e86b5-27c1-46c7-becf-cafb48f5913a"
      },
      "source": [
        "N_inputs = int(X.get_shape()[1])\n",
        "stddev = 2 / np.sqrt(N_inputs)\n",
        "print(stddev)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.07142857142857142\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deSoMbvlfVAa",
        "outputId": "41f7efde-0719-4f8a-bcdc-0194b863b70a"
      },
      "source": [
        "#tf.truncated_normal() selects random numbers from a normal distribution \n",
        "#whose mean is close to 0 and values are close to 0. For example, from -0.1 to 0.1. \n",
        "#It's called truncated because your cutting off the tails from a normal distribution.\n",
        "init = tf.truncated_normal((N_inputs, 200), stddev=stddev)\n",
        "print(init)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"truncated_normal:0\", shape=(784, 200), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMcjS2cqNhaF"
      },
      "source": [
        "###**3. Let's define a function for creating the layers of out DNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aJ8qPCokSNa"
      },
      "source": [
        "def Details(x, y, w,b,z):\n",
        "  print(\"-------------------------------------------------------------------------\")\n",
        "  print(\"Shape is : \" + str(x))\n",
        "  print(\"The number of inputs : \" + str(x[1]))\n",
        "  print(\"The number of output neurons : \" + str(y))\n",
        "  print(\"Weights : \" + str(w))\n",
        "  print(\"Bias : \" + str(b))\n",
        "  print(\"Z  : \" + str(z))\n",
        "  print(\"-------------------------------------------------------------------------\")\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnweWbM2Noib"
      },
      "source": [
        "def neuron_layer(X, n_neurons, name, activation=None):\n",
        "    with tf.name_scope(name):\n",
        "        n_inputs = int(X.get_shape()[1])\n",
        "        stddev = 2 / np.sqrt(n_inputs)\n",
        "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
        "        W = tf.Variable(init, name=\"kernel\")\n",
        "        b = tf.Variable(tf.zeros([n_neurons]), name=\"bias\")\n",
        "        Z = tf.matmul(X, W) + b\n",
        "        Details(X.get_shape(),n_neurons, W.get_shape(), b.get_shape(), Z.get_shape())\n",
        "        if activation is not None:\n",
        "            return activation(Z)\n",
        "        else:\n",
        "            return Z"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I51g8cDeNvfx",
        "outputId": "5edb54a2-b180-40b5-cbc2-153251fe295e"
      },
      "source": [
        "y = tf.nn.relu(0.6)\n",
        "with tf.Session() as s:\n",
        "    print(y.eval())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kq463pXOQiXW",
        "outputId": "f4367e1d-ee57-49fe-89c6-01b58852b50f"
      },
      "source": [
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",activation=tf.nn.relu)\n",
        "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",activation=tf.nn.relu)\n",
        "    hidden3 = neuron_layer(hidden2, n_hidden3, name=\"hidden3\",activation=tf.nn.relu)\n",
        "    logits = neuron_layer(hidden3, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------------\n",
            "Shape is : (?, 784)\n",
            "The number of inputs : 784\n",
            "The number of output neurons : 100\n",
            "Weights : (784, 100)\n",
            "Bias : (100,)\n",
            "Z  : (?, 100)\n",
            "-------------------------------------------------------------------------\n",
            "-------------------------------------------------------------------------\n",
            "Shape is : (?, 100)\n",
            "The number of inputs : 100\n",
            "The number of output neurons : 200\n",
            "Weights : (100, 200)\n",
            "Bias : (200,)\n",
            "Z  : (?, 200)\n",
            "-------------------------------------------------------------------------\n",
            "-------------------------------------------------------------------------\n",
            "Shape is : (?, 200)\n",
            "The number of inputs : 200\n",
            "The number of output neurons : 300\n",
            "Weights : (200, 300)\n",
            "Bias : (300,)\n",
            "Z  : (?, 300)\n",
            "-------------------------------------------------------------------------\n",
            "-------------------------------------------------------------------------\n",
            "Shape is : (?, 300)\n",
            "The number of inputs : 300\n",
            "The number of output neurons : 10\n",
            "Weights : (300, 10)\n",
            "Bias : (10,)\n",
            "Z  : (?, 10)\n",
            "-------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaXNWD1rNpi8"
      },
      "source": [
        "###**4. Using dense instead of neuron_layer function( )**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj2Gp830SfIp"
      },
      "source": [
        "####**4.1 Defining Placeholders**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RBbT5ntSd5C"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iOGy0rdSs89"
      },
      "source": [
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",activation=tf.nn.relu)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",activation=tf.nn.relu)\n",
        "    hidden3 = tf.layers.dense(hidden2, n_hidden3, name=\"hidden3\",activation=tf.nn.relu)\n",
        "    logits = tf.layers.dense(hidden3, n_outputs, name=\"outputs\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdGMBOzeN-uH"
      },
      "source": [
        "###**5. Defining the loss function**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96IcM_hnN9zF"
      },
      "source": [
        "# For regression:\n",
        "# with tf.name_scope(\"regloss\"):\n",
        "#     loss = tf.reduce_mean(tf.square(y-logits), name=\"regloss\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiYdAwA2TENK"
      },
      "source": [
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCTI978IOCq2"
      },
      "source": [
        "###**6. Defining the gradient descent optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qt3eijkOJqj"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-znFiXHUOKCn"
      },
      "source": [
        "###**7. Specifying how to evaluate the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Slpej7cVOSWs",
        "outputId": "163447b2-04c8-41b8-c406-18fc4e2d82b8"
      },
      "source": [
        "result = tf.nn.in_top_k([[0.1, 0.8, 0.3, 0.6, 0.5]], [4], 2)\n",
        "result"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'in_top_k/InTopKV2:0' shape=(1,) dtype=bool>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNvJRkrzvhfx",
        "outputId": "3c10ffe3-ebed-45d1-8710-5b0acde7b707"
      },
      "source": [
        "with tf.Session() as s:\n",
        "    print(result.eval())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxjOCM1ETfCR",
        "outputId": "dee81615-d821-435e-91ad-ae0c67192d8e"
      },
      "source": [
        "#returns index of highest value\n",
        "np.argmax([0.1, 0.9, 0.3, 0.2, 0.5, 0.8,55])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtZyrB2MTlw3"
      },
      "source": [
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sP9RrjIeOSkg"
      },
      "source": [
        "###**8. Initialize variables and create saver**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31j9Mdi5Obsh"
      },
      "source": [
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArpSdA_5Ode8"
      },
      "source": [
        "###**9. Define the number of epochs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGPYijjVOowo"
      },
      "source": [
        "n_epochs = 40\n",
        "batch_size = 50"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BQ_8W2Rv1rY",
        "outputId": "46c66c07-6b57-40f1-f2a3-0ea2ae7b5f1f"
      },
      "source": [
        "mnist.train.num_examples // batch_size"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJlBTA9lOpVY"
      },
      "source": [
        "###**10. Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v83ZfZwTOsZp",
        "outputId": "ed6996ee-762c-4fc4-fff9-de00d1db52c9"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for iteration in range(mnist.train.num_examples // batch_size):\n",
        "            X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,\n",
        "                                            y: mnist.validation.labels})\n",
        "        print(epoch, \"Train accuracy:\", acc_train, \"Val accuracy:\", acc_val)\n",
        "\n",
        "    save_path = saver.save(sess, \"model_ckps/my_model_final.ckpt\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Train accuracy: 0.86 Val accuracy: 0.8954\n",
            "1 Train accuracy: 0.92 Val accuracy: 0.917\n",
            "2 Train accuracy: 0.92 Val accuracy: 0.9282\n",
            "3 Train accuracy: 0.96 Val accuracy: 0.9376\n",
            "4 Train accuracy: 0.94 Val accuracy: 0.9454\n",
            "5 Train accuracy: 0.9 Val accuracy: 0.9504\n",
            "6 Train accuracy: 0.94 Val accuracy: 0.9556\n",
            "7 Train accuracy: 0.96 Val accuracy: 0.9578\n",
            "8 Train accuracy: 0.96 Val accuracy: 0.9628\n",
            "9 Train accuracy: 0.98 Val accuracy: 0.964\n",
            "10 Train accuracy: 0.98 Val accuracy: 0.964\n",
            "11 Train accuracy: 0.94 Val accuracy: 0.9664\n",
            "12 Train accuracy: 1.0 Val accuracy: 0.9676\n",
            "13 Train accuracy: 0.94 Val accuracy: 0.9668\n",
            "14 Train accuracy: 1.0 Val accuracy: 0.9702\n",
            "15 Train accuracy: 1.0 Val accuracy: 0.9714\n",
            "16 Train accuracy: 1.0 Val accuracy: 0.9696\n",
            "17 Train accuracy: 1.0 Val accuracy: 0.9714\n",
            "18 Train accuracy: 1.0 Val accuracy: 0.9728\n",
            "19 Train accuracy: 1.0 Val accuracy: 0.9736\n",
            "20 Train accuracy: 1.0 Val accuracy: 0.974\n",
            "21 Train accuracy: 1.0 Val accuracy: 0.9748\n",
            "22 Train accuracy: 1.0 Val accuracy: 0.975\n",
            "23 Train accuracy: 1.0 Val accuracy: 0.9754\n",
            "24 Train accuracy: 1.0 Val accuracy: 0.975\n",
            "25 Train accuracy: 1.0 Val accuracy: 0.9748\n",
            "26 Train accuracy: 1.0 Val accuracy: 0.9764\n",
            "27 Train accuracy: 1.0 Val accuracy: 0.9762\n",
            "28 Train accuracy: 0.98 Val accuracy: 0.9762\n",
            "29 Train accuracy: 1.0 Val accuracy: 0.9764\n",
            "30 Train accuracy: 1.0 Val accuracy: 0.9776\n",
            "31 Train accuracy: 1.0 Val accuracy: 0.977\n",
            "32 Train accuracy: 0.98 Val accuracy: 0.9764\n",
            "33 Train accuracy: 1.0 Val accuracy: 0.975\n",
            "34 Train accuracy: 0.98 Val accuracy: 0.9772\n",
            "35 Train accuracy: 1.0 Val accuracy: 0.9754\n",
            "36 Train accuracy: 1.0 Val accuracy: 0.9768\n",
            "37 Train accuracy: 1.0 Val accuracy: 0.9766\n",
            "38 Train accuracy: 1.0 Val accuracy: 0.9758\n",
            "39 Train accuracy: 1.0 Val accuracy: 0.9774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsK21ohKOsw1"
      },
      "source": [
        "###**11. Using the Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-U01XYOOctL",
        "outputId": "fa66fdfb-952f-44af-9c39-d89681d97f53"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    saver.restore(sess, \"model_ckps/my_model_final.ckpt\") # or better, use save_path\n",
        "    X_new_scaled = mnist.test.images[:20]\n",
        "    y_actual = mnist.test.labels[:20]\n",
        "    Z = logits.eval(feed_dict={X: X_new_scaled})\n",
        "    y_pred = np.argmax(Z, axis=1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model_ckps/my_model_final.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zl0BYEm8UGmO",
        "outputId": "14655094-6372-4812-cf5c-92a9ae3eb86c"
      },
      "source": [
        "!ls -l model_ckps/"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 672\n",
            "-rw-r--r-- 1 root root     95 Dec  4 17:48 checkpoint\n",
            "-rw-r--r-- 1 root root 648040 Dec  4 17:48 my_model_final.ckpt.data-00000-of-00001\n",
            "-rw-r--r-- 1 root root    367 Dec  4 17:48 my_model_final.ckpt.index\n",
            "-rw-r--r-- 1 root root  38016 Dec  4 17:48 my_model_final.ckpt.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8lF54PfUK2O",
        "outputId": "43f5f70d-dacb-4d29-951b-32e5156847d9"
      },
      "source": [
        "print(\"Predicted classes:\", y_pred)\n",
        "print(\"Actual classes:   \",  y_actual)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted classes: [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n",
            "Actual classes:    [7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}